{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data to (0,1) & (-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler_0_1 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_m1_1 = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "X_0 = scaler_0_1.fit_transform(X)\n",
    "X_1 = scaler_m1_1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a simple split, where we'll use 60000 examples for training and 10000 for testing/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use a simple split, where we'll use 60000 examples for training and 10000 for testing/validation.\n",
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(X_0, y, test_size=10000, random_state=0)\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y, test_size=10000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method that prints accuracy & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_accuracy_confusion_matrix(y_true, y_pred):\n",
    "    print('Accuracy:', accuracy_score(y_true=y_true, y_pred=y_pred))\n",
    "    print('Confusion Matrix\\n', confusion_matrix(y_true=y_true, y_pred=y_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the split datasets above, execute SVM for linear and rbf kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Kernel for (0,1) normalization\n",
      "Accuracy: 0.936\n",
      "Confusion Matrix\n",
      " [[ 969    0    2    3    1   11    7    0    1    2]\n",
      " [   0 1125    4    2    1    2    0    3    4    0]\n",
      " [   6   10  980   10   11    2    4    7    8    2]\n",
      " [   2    7   34  919    2   20    0    5   16    8]\n",
      " [   1    2    6    1  907    1    7    9    1   27]\n",
      " [   9    3   10   29    7  782    7    0    9    7]\n",
      " [   7    1    8    0    8   14  947    0    4    0]\n",
      " [   5    6   16    7   11    4    1  985    1   28]\n",
      " [   2   12   12   25    5   14    7    1  875   10]\n",
      " [   2    4    5    9   37    8    0   25    8  871]] \n",
      "\n",
      "RBF Kernel for (0,1) normalization\n",
      "Accuracy: 0.9777\n",
      "Confusion Matrix\n",
      " [[ 988    0    1    0    0    3    3    0    1    0]\n",
      " [   0 1134    2    0    1    0    0    2    1    1]\n",
      " [   1    0 1020    2    4    0    2    5    5    1]\n",
      " [   0    1   11  973    0    9    0    4   13    2]\n",
      " [   1    1    1    0  946    1    1    4    0    7]\n",
      " [   0    1    3    7    1  838    7    0    5    1]\n",
      " [   5    0    0    0    3    5  974    0    2    0]\n",
      " [   1    3    7    0    9    1    1 1033    0    9]\n",
      " [   0    5    3    5    2    2    3    0  937    6]\n",
      " [   1    1    1    4   13    4    1    9    1  934]] \n",
      "\n",
      "Linear Kernel for (-1,1) normalization\n",
      "Accuracy: 0.9286\n",
      "Confusion Matrix\n",
      " [[ 967    0    2    1    1   13    9    0    3    0]\n",
      " [   0 1124    7    2    1    2    0    2    3    0]\n",
      " [   7   15  967   13   12    2    7    6   10    1]\n",
      " [   1    7   34  914    2   24    0    6   18    7]\n",
      " [   2    1    7    1  901    1    8    9    1   31]\n",
      " [  10    4   11   30    7  778    7    1    8    7]\n",
      " [  10    1   11    1   13   17  931    0    5    0]\n",
      " [   6    6   18   15   11    3    1  978    1   25]\n",
      " [   3   13   16   27    6   19    6    2  861   10]\n",
      " [   3    4    5    7   41    7    1   27    9  865]] \n",
      "\n",
      "RBF Kernel for (-1,1) normalization\n",
      "Accuracy: 0.9777\n",
      "Confusion Matrix\n",
      " [[ 988    0    1    0    0    3    3    0    1    0]\n",
      " [   0 1134    2    0    1    0    0    2    1    1]\n",
      " [   1    0 1020    2    4    0    2    5    5    1]\n",
      " [   0    1   11  973    0    9    0    4   13    2]\n",
      " [   1    1    1    0  946    1    1    4    0    7]\n",
      " [   0    1    3    7    1  838    7    0    5    1]\n",
      " [   5    0    0    0    3    5  974    0    2    0]\n",
      " [   1    3    7    0    9    1    1 1033    0    9]\n",
      " [   0    5    3    5    2    2    3    0  937    6]\n",
      " [   1    1    1    4   13    4    1    9    1  934]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_rbf = SVC(kernel='rbf')\n",
    "\n",
    "model_linear.fit(X_0_train, y_0_train)\n",
    "y_pred = model_linear.predict(X_0_test)\n",
    "print('Linear Kernel for (0,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_0_test, y_pred)\n",
    "\n",
    "model_rbf.fit(X_0_train, y_0_train)\n",
    "y_pred = model_rbf.predict(X_0_test)\n",
    "print('RBF Kernel for (0,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_0_test, y_pred)\n",
    "\n",
    "model_linear.fit(X_1_train, y_1_train)\n",
    "y_pred = model_linear.predict(X_1_test)\n",
    "print('Linear Kernel for (-1,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_1_test, y_pred)\n",
    "\n",
    "model_rbf.fit(X_1_train, y_1_train)\n",
    "y_pred = model_rbf.predict(X_1_test)\n",
    "print('RBF Kernel for (-1,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_1_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to extract the best hyper parameters, use Grid Search for SVM with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train):\n",
    "    # Creating a KFold object with 5 splits\n",
    "    folds = KFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "    \n",
    "    # Specify range of hyperparameters\n",
    "    hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4], 'C': [5,10]}]\n",
    "    \n",
    "    # Specify model\n",
    "    model = SVC(kernel='rbf')\n",
    "    \n",
    "    # Set up GridSearchCV()\n",
    "    model_cv = GridSearchCV(estimator = model,\n",
    "                            param_grid = hyper_params,\n",
    "                            scoring= 'accuracy',\n",
    "                            cv = folds,\n",
    "                            verbose = 1,\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=4)\n",
    "    \n",
    "    # Fit the model\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # Cross Validation results\n",
    "    cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "    print(cv_results)\n",
    "    \n",
    "    \n",
    "    # Print the optimal accuracy score and hyperparameters\n",
    "    best_score = model_cv.best_score_\n",
    "    best_hyperparams = model_cv.best_params_\n",
    "    \n",
    "    print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply grid search for (0,1) normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0     363.364452      6.725101       165.236679       10.694748       5   \n",
      "1     434.663380     32.911280       225.978360       22.853936       5   \n",
      "2     848.417112     36.132054       364.932385        9.025371       5   \n",
      "3     292.935847      9.668948       170.052067        5.066450      10   \n",
      "4     325.692875      4.533128       196.359152        9.759201      10   \n",
      "5     611.516203     58.077355       292.725572       44.495067      10   \n",
      "\n",
      "  param_gamma                      params  split0_test_score  \\\n",
      "0        0.01     {'C': 5, 'gamma': 0.01}           0.981583   \n",
      "1       0.001    {'C': 5, 'gamma': 0.001}           0.951417   \n",
      "2      0.0001   {'C': 5, 'gamma': 0.0001}           0.926083   \n",
      "3        0.01    {'C': 10, 'gamma': 0.01}           0.982250   \n",
      "4       0.001   {'C': 10, 'gamma': 0.001}           0.955083   \n",
      "5      0.0001  {'C': 10, 'gamma': 0.0001}           0.931917   \n",
      "\n",
      "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
      "0           0.979750           0.978667  ...         0.980967        0.001508   \n",
      "1           0.947417           0.943667  ...         0.948033        0.002581   \n",
      "2           0.924500           0.918500  ...         0.923867        0.003402   \n",
      "3           0.980500           0.978833  ...         0.981333        0.001492   \n",
      "4           0.952333           0.950667  ...         0.953883        0.002033   \n",
      "5           0.930250           0.926667  ...         0.929867        0.002079   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                2            0.998125            0.998167   \n",
      "1                4            0.954396            0.955708   \n",
      "2                6            0.925687            0.926021   \n",
      "3                1            0.999583            0.999750   \n",
      "4                3            0.962896            0.963938   \n",
      "5                5            0.932958            0.933187   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0            0.997896            0.998042            0.998146   \n",
      "1            0.956063            0.955417            0.954833   \n",
      "2            0.927396            0.926646            0.925583   \n",
      "3            0.999583            0.999500            0.999646   \n",
      "4            0.964250            0.963021            0.962958   \n",
      "5            0.934333            0.933771            0.932917   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "0          0.998075         0.000099  \n",
      "1          0.955283         0.000599  \n",
      "2          0.926267         0.000676  \n",
      "3          0.999612         0.000083  \n",
      "4          0.963413         0.000566  \n",
      "5          0.933433         0.000543  \n",
      "\n",
      "[6 rows x 22 columns]\n",
      "The best test score is 0.9813333333333334 corresponding to hyperparameters {'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "grid_search(X_0_train, y_0_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply grid search for (-1,1) normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0     993.658104     60.722012       279.927370        3.001816       5   \n",
      "1     328.816208      8.526209       173.200430        2.727178       5   \n",
      "2     560.992705     23.156123       277.633363        7.351470       5   \n",
      "3    1057.380470     47.105132       358.286031       20.506534      10   \n",
      "4     336.114696     15.946812       192.357687        2.743108      10   \n",
      "5     575.514290     40.576777       274.885116       58.242152      10   \n",
      "\n",
      "  param_gamma                      params  split0_test_score  \\\n",
      "0        0.01     {'C': 5, 'gamma': 0.01}           0.984833   \n",
      "1       0.001    {'C': 5, 'gamma': 0.001}           0.973917   \n",
      "2      0.0001   {'C': 5, 'gamma': 0.0001}           0.940500   \n",
      "3        0.01    {'C': 10, 'gamma': 0.01}           0.984833   \n",
      "4       0.001   {'C': 10, 'gamma': 0.001}           0.976917   \n",
      "5      0.0001  {'C': 10, 'gamma': 0.0001}           0.945333   \n",
      "\n",
      "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
      "0           0.982750           0.982667  ...         0.984267        0.001320   \n",
      "1           0.971917           0.970750  ...         0.972983        0.001536   \n",
      "2           0.937417           0.933750  ...         0.937500        0.002385   \n",
      "3           0.982750           0.982667  ...         0.984267        0.001320   \n",
      "4           0.974583           0.973917  ...         0.976033        0.001509   \n",
      "5           0.942500           0.937500  ...         0.941983        0.002743   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                1            1.000000            1.000000   \n",
      "1                4            0.986104            0.985896   \n",
      "2                6            0.941083            0.941396   \n",
      "3                1            1.000000            1.000000   \n",
      "4                3            0.992792            0.993062   \n",
      "5                5            0.947063            0.948167   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0            1.000000            1.000000            1.000000   \n",
      "1            0.985854            0.985604            0.985333   \n",
      "2            0.943083            0.942250            0.940708   \n",
      "3            1.000000            1.000000            1.000000   \n",
      "4            0.992667            0.992521            0.992563   \n",
      "5            0.949063            0.948271            0.947479   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "0          1.000000         0.000000  \n",
      "1          0.985758         0.000265  \n",
      "2          0.941704         0.000857  \n",
      "3          1.000000         0.000000  \n",
      "4          0.992721         0.000195  \n",
      "5          0.948008         0.000690  \n",
      "\n",
      "[6 rows x 22 columns]\n",
      "The best test score is 0.9842666666666666 corresponding to hyperparameters {'C': 5, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "grid_search(X_1_train, y_1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SVM model with kernel=rbf, C=5, gamma=0.01. For all the train/predict from this point forward we use the (-1,1) normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf', C=5, gamma=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit SVM Model without PCA transformation initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 479.74951577186584 secs\n",
      "RBF Kernel for (-1,1) normalization\n",
      "Accuracy: 0.9777\n",
      "Confusion Matrix\n",
      " [[ 988    0    1    0    0    3    3    0    1    0]\n",
      " [   0 1134    2    0    1    0    0    2    1    1]\n",
      " [   1    0 1020    2    4    0    2    5    5    1]\n",
      " [   0    1   11  973    0    9    0    4   13    2]\n",
      " [   1    1    1    0  946    1    1    4    0    7]\n",
      " [   0    1    3    7    1  838    7    0    5    1]\n",
      " [   5    0    0    0    3    5  974    0    2    0]\n",
      " [   1    3    7    0    9    1    1 1033    0    9]\n",
      " [   0    5    3    5    2    2    3    0  937    6]\n",
      " [   1    1    1    4   13    4    1    9    1  934]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.fit(X_1_train, y_1_train)\n",
    "print('Elapsed time: %s secs'%(time.time()-start_time))\n",
    "\n",
    "y_pred = model_rbf.predict(X_1_test)\n",
    "print('RBF Kernel for (-1,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_1_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA transformation to the (-1,1) normalized dataset with 0.95 number of components and fit and predict the SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_1_train = scaler.fit_transform(X_1_train)\n",
    "X_1_test = scaler.fit_transform(X_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 327)\n",
      "Elapsed time using 327 components: 2230.0537192821503 secs\n",
      "RBF Kernel for (-1,1) normalization\n",
      "Accuracy: 0.8934\n",
      "Confusion Matrix\n",
      " [[ 925    0   65    1    0    1    3    0    1    0]\n",
      " [   0 1120   17    0    0    0    0    2    1    1]\n",
      " [   1    0 1028    1    1    0    0    3    5    1]\n",
      " [   0    0  149  842    0    6    0    4   10    2]\n",
      " [   1    0   96    0  857    0    0    2    1    5]\n",
      " [   0    0  108    9    0  736    5    2    2    1]\n",
      " [   2    0  135    0    1    5  844    0    2    0]\n",
      " [   1    4  170    0    4    1    0  877    0    7]\n",
      " [   0    3  103    7    0    6    1    0  840    3]\n",
      " [   0    0   74    7    8    1    0   12    2  865]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(.95)\n",
    "\n",
    "pca.fit(X_1_train)\n",
    "X_train_pca = pca.transform(X_1_train)\n",
    "X_test_pca = pca.transform(X_1_test)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_pca, y_1_train)\n",
    "print('Elapsed time using %s components: %s secs'%(X_train_pca.shape[1], time.time()-start_time))\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('RBF Kernel for (-1,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_1_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA transformation to the (-1,1) normalized dataset with 0.65 number of components and fit and predict the SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 78)\n",
      "Elapsed time using 78 components: 290.6317615509033 secs\n",
      "RBF Kernel for (-1,1) normalization\n",
      "Accuracy: 0.9543\n",
      "Confusion Matrix\n",
      " [[ 967    0   21    1    0    1    5    0    1    0]\n",
      " [   0 1125   10    1    0    0    0    2    2    1]\n",
      " [   3    0 1027    2    1    0    0    3    2    2]\n",
      " [   0    0   41  951    0    5    0    3   11    2]\n",
      " [   1    0   41    0  910    1    0    5    0    4]\n",
      " [   1    0   21   11    1  820    5    2    2    0]\n",
      " [   2    0   50    0    1    5  931    0    0    0]\n",
      " [   0    2   58    0    2    0    0  996    0    6]\n",
      " [   0    1   40    6    0    2    2    2  905    5]\n",
      " [   0    1   28    8    9    1    0    9    2  911]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(.65)\n",
    "\n",
    "pca.fit(X_1_train)\n",
    "X_train_pca = pca.transform(X_1_train)\n",
    "X_test_pca = pca.transform(X_1_test)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_pca, y_1_train)\n",
    "print('Elapsed time using %s components: %s secs'%(X_train_pca.shape[1], time.time()-start_time))\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('RBF Kernel for (-1,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_1_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA transformation to the (-1,1) normalized dataset with 0.35 number of components and fit and predict the SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 17)\n",
      "Elapsed time using 17 components: 29.632370233535767 secs\n",
      "RBF Kernel for (-1,1) normalization\n",
      "Accuracy: 0.9665\n",
      "Confusion Matrix\n",
      " [[ 990    0    0    2    0    1    2    0    1    0]\n",
      " [   0 1129    3    2    0    0    0    2    2    3]\n",
      " [   2    0 1010    8    3    3    1    4    6    3]\n",
      " [   1    4   18  946    1    9    1    6   22    5]\n",
      " [   1    0    3    1  932    0    0    4    2   19]\n",
      " [   2    1    2   11    2  828    7    1    7    2]\n",
      " [   3    0    1    0    2    8  974    0    1    0]\n",
      " [   1    3    8    4    3    1    0 1029    1   14]\n",
      " [   2    7    3   15    1   16    4    3  904    8]\n",
      " [   0    0    2   11   13    4    0   11    5  923]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(.35)\n",
    "\n",
    "pca.fit(X_1_train)\n",
    "X_train_pca = pca.transform(X_1_train)\n",
    "X_test_pca = pca.transform(X_1_test)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_pca, y_1_train)\n",
    "print('Elapsed time using %s components: %s secs'%(X_train_pca.shape[1], time.time()-start_time))\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('RBF Kernel for (-1,1) normalization')\n",
    "print_accuracy_confusion_matrix(y_1_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
